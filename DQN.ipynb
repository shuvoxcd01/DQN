{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from random import randrange, choice, choices, random\n",
    "import os\n",
    "from ale_python_interface import ALEInterface\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom_path = os.path.join(os.path.dirname(os.path.abspath('__file__')),'ROMs','Space_Invaders.bin')\n",
    "\n",
    "if not os.path.exists(rom_path):\n",
    "    print(\"Invalid ROM path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ale = ALEInterface()\n",
    "\n",
    "ale.setBool(b'display_screen', True)\n",
    "#ale.setBool(b'sound',True)\n",
    "ale.setInt(b'frame_skip', 3)\n",
    "#ale.setBool(b'blablabla', True)\n",
    "ale.setBool(b'color_averaging', True)\n",
    "\n",
    "ale.loadROM(bytes(rom_path, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions = ale.getLegalActionSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self):\n",
    "        self.last_preprocessed_seq = None\n",
    "        \n",
    "    def initialize_last_preprocessed_seq(self, sequence):\n",
    "        last_screen = sequence[-1]\n",
    "        resized_screen = cv2.resize(last_screen, dsize=(84,110), interpolation = cv2.INTER_AREA)\n",
    "        cropped_screen = resized_screen[17:110-9,:]\n",
    "        self.last_preprocessed_seq = np.empty((84,84,4))\n",
    "        for i in range(4):\n",
    "            self.last_preprocessed_seq[:,:,i] = cropped_screen\n",
    "        \n",
    "        return self.last_preprocessed_seq\n",
    "                                     \n",
    "    def phi(self, sequence):\n",
    "        if self.last_preprocessed_seq is None:\n",
    "            return self.initialize_last_preprocessed_seq(sequence)\n",
    "            \n",
    "        last_screen = sequence[-1]\n",
    "        resized_screen = cv2.resize(last_screen, dsize=(84,110), interpolation = cv2.INTER_AREA)\n",
    "        cropped_screen = resized_screen[17:110-9,:]\n",
    "        \n",
    "        preprocessed_seq = np.empty((84,84,4))\n",
    "        preprocessed_seq[:,:,:3] = self.last_preprocessed_seq[:,:,1:]\n",
    "            \n",
    "        preprocessed_seq[:,:,-1] = cropped_screen\n",
    "\n",
    "        self.last_preprocessed_seq = preprocessed_seq\n",
    "\n",
    "        return preprocessed_seq\n",
    "    \n",
    "    def preprocess(self, sequence):\n",
    "        return self.phi(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=(8,8), strides=(4,4), input_shape=(84,84,4), activation='relu'))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(4,4), strides=(2,2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dense(units=len(legal_actions)))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=RMSprop())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(get_Q()).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_epsilon(epsilon):\n",
    "    if epsilon < 0.1:\n",
    "        epsilon = 0.1\n",
    "        return\n",
    "    elif epsilon == 0.1:\n",
    "        return\n",
    "    else:\n",
    "        epsilon -= 9.000000000000001e-07 # epsilon -= (1-0.1) / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN():\n",
    "    minibatch_size = 32\n",
    "    D = deque([], maxlen=1000000)\n",
    "    Q = get_Q()\n",
    "    epsilon = 1.\n",
    "    screen = np.empty((210,160))\n",
    "    preprocessor = Preprocessor()\n",
    "    gamma = 0.9\n",
    "    \n",
    "    for num_episode in range(10000):\n",
    "        ale.reset_game()\n",
    "        ale.getScreenGrayscale(screen)\n",
    "        sequence = [screen]\n",
    "        preprocessed_input = preprocessor.phi(sequence)\n",
    "        while not ale.game_over():\n",
    "            if random() <= epsilon:\n",
    "                action = choice(legal_actions)\n",
    "            else:\n",
    "                action = np.argmax(Q.predict(np.expand_dims(preprocessed_input, 0))[0])\n",
    "            update_epsilon(epsilon)\n",
    "            reward = ale.act(action)\n",
    "            ale.getScreenGrayscale(screen)\n",
    "            sequence.append(action)\n",
    "            sequence.append(screen)\n",
    "            previous_input = preprocessed_input\n",
    "            preprocessed_input = preprocessor.phi(sequence)\n",
    "            D.append((previous_input,action, reward, preprocessed_input, ale.game_over()))\n",
    "            if len(D) > minibatch_size:\n",
    "                X = []\n",
    "                target = []\n",
    "                sample_minibatch = choices(D, k=minibatch_size)\n",
    "                \n",
    "                for previous_input,action, reward, next_input, is_terminal in sample_minibatch:\n",
    "                    q_value = reward\n",
    "                    if not is_terminal:\n",
    "                        q_value += gamma * np.amax(Q.predict(np.expand_dims(next_input,0)))\n",
    "                    prediction = Q.predict(np.expand_dims(previous_input, 0))[0]\n",
    "                    prediction[action] = q_value\n",
    "                    target.append(prediction)\n",
    "                    X.append(previous_input)\n",
    "\n",
    "                Q.fit(x=np.array(X), y= np.array(target), epochs=1)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    ale.reset_game()\n",
    "    while not ale.game_over():\n",
    "        reward = ale.act(choice(legal_actions))\n",
    "        #print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    obs, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    time.sleep(0.01)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ale.reset_game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
